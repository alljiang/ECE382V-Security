{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 4, Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data in the following two CSVs:\n",
    "# data/exercise2/lab4_normal_data.csv\n",
    "# data/exercise2/lab4_malicious_data.csv\n",
    "# The first consists completely of normal data, while the second consists completely of malicious data\n",
    "# Note: Both sets of data contain the same features used in Exercise 1; the data has already been preprocessed\n",
    "# (i.e., you can keep all the features and there are no labels in the CSVs)\n",
    "\n",
    "# CODE HERE\n",
    "df_normal = pd.read_csv('data/exercise2/lab4_normal_data.csv')\n",
    "df_malicious = pd.read_csv('data/exercise2/lab4_malicious_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56001\n"
     ]
    }
   ],
   "source": [
    "# Create 15 datasets, where the ith dataset consists of:\n",
    "# - all normal data\n",
    "# - only the ith malicious datapoint\n",
    "\n",
    "# CODE HERE\n",
    "datasets = []\n",
    "for i in range(len(df_malicious)):\n",
    "    df = df_normal.copy()\n",
    "    datasets.append(pd.concat([df, df_malicious.iloc[[i]]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.12306769278176743, 4)\n",
      "(-0.11853696621166065, 11)\n",
      "(-0.10831943336082428, 14)\n",
      "(-0.0959996446517859, 10)\n",
      "(-0.08994705272120196, 0)\n",
      "(-0.08873643044853996, 12)\n",
      "(-0.07216347589197358, 2)\n",
      "(-0.0686318205034333, 8)\n",
      "(-0.05795377909685617, 13)\n",
      "(-0.02323794487947306, 3)\n",
      "(0.08432400194851936, 6)\n",
      "(0.09011002809410179, 9)\n",
      "(0.09456909324692842, 1)\n",
      "(0.10300653794818693, 7)\n",
      "(0.11566603824571631, 5)\n"
     ]
    }
   ],
   "source": [
    "# For each dataset, run isolation forests\n",
    "#\n",
    "# Use the following evaluation metric:\n",
    "# - rank the anomalousness of each datapoint using the isolation forest\n",
    "# - record the list index of each attack datapoint when sorting from most to least unusual\n",
    "#     - e.g., if the attack datapoint is at index 0 in the list, we want to record the value 0\n",
    "#\n",
    "# Note: don't worry about ties in ranking\n",
    "# Hint: What is the difference between isolation forest's 'decision_function' and 'predict' methods? \n",
    "\n",
    "# CODE HERE\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "anomalousness = []\n",
    "\n",
    "for i in range(len(datasets)):\n",
    "    df = datasets[i]\n",
    "    clf = IsolationForest()\n",
    "    clf.fit(df)\n",
    "    scores = clf.decision_function(df)\n",
    "    anomalousness.append((scores[len(df_normal)], i))\n",
    "\n",
    "# sort anomalousness by the first element of each tuple from least to greatest\n",
    "anomalousness.sort(key=lambda x: x[0])\n",
    "for i in range(len(anomalousness)):\n",
    "    print(anomalousness[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions:\n",
    "1) Why is there no separate training and test set?\n",
    "\n",
    "The model is focused on evaluating the ability to detect anomalies, rather than training for detecting specific situations. Since there's only one malicious data point in each dataset, the model would overfit to that specific data point if we used a training and test set.\n",
    "\n",
    "2) What is the metric measuring?  What would be a perfect score?  Bonus: What is the expected performance of an outlier detector that assigns a random score to each datapoint?\n",
    "\n",
    "The metric is measuring the anomaly score. A perfect score would be -1.0.\n",
    "The expected performance of an outlier detector that assigns a random score to each datapoint would be poor and would result in many false positives, and about 50% of the malicious data points would be detected.\n",
    "\n",
    "3) How well does the isolation forest perform compared to a perfect score? Bonus: How well does the isolation forest perform compared to a random detector?\n",
    "\n",
    "The isolation forest is not as confident as a perfect score, but it scored most of the malicious data points as anomalies. The isolation forest performs better than a random detector because it detects more than half of the malicious data points.\n",
    "\n",
    "4) What are some issues that would prevent this model from being practically deployed?\n",
    "\n",
    "The false positive rate is high for this model, so in a real world scenario, the system would have trouble running with benign data. The model would need to be trained on more data to reduce the false positive rate.\n",
    "\n",
    "5) What might happen if we inject five attack datapoints at a time?  What might happen if we inject 100 attack datapoints at a time?\n",
    "\n",
    "If we inject five attack datapoints at a time, the model would be able to detect the anomalies with a slightly higher confidence and a lower false positive rate. If we inject 100 attack datapoints at a time, the model would be able to detect the anomalies with an even higher confidence and a lower false positive rate.\n",
    "\n",
    "6) What is the effect of the parameters max_features and max_samples?  What other parameters could you adjust to change performance?\n",
    "\n",
    "max_features: changes the number of features to consider when evaluating the split. Less features means less splits, which would make the model faster to train, but possibly less accurate (depending on the number of relevant features).\n",
    "max_samples: changes the number of samples used to evaluate the split. Less samples = faster training and more sensitive to outliers.\n",
    "\n",
    "Other parameters:\n",
    "contamination: defines the proportion of outliers in the dataset, used when fitting to determine the scoring threshold.\n",
    "n_estimators: number of base estimators to use in the ensemble. More estimators = slower training, but possibly more accurate.\n",
    "\n",
    "Bonus: What are some alternative anomaly detection models one could use instead of an isolation forest? Try one of these alternatives and compare performance.\n",
    "\n",
    "An alternative is a one-class SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-3577.25244812906, 2)\n",
      "(-2347.6318164347886, 10)\n",
      "(-1805.0377441662731, 8)\n",
      "(-1525.0443273691872, 4)\n",
      "(-755.0639751976723, 0)\n",
      "(-662.9233153680761, 11)\n",
      "(-662.9233153680761, 12)\n",
      "(5.282121258025654, 9)\n",
      "(6.907916265347012, 6)\n",
      "(7.988416205967951, 1)\n",
      "(101.50959173818774, 3)\n",
      "(427.9006711644415, 14)\n",
      "(1756.2576656214605, 5)\n",
      "(2127.2760778520624, 7)\n",
      "(2188.0793434177667, 13)\n"
     ]
    }
   ],
   "source": [
    "# one-class SVM\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "anomalousness = []\n",
    "\n",
    "for i in range(len(datasets)):\n",
    "    df = datasets[i]\n",
    "    clf = OneClassSVM()\n",
    "    clf.fit(df)\n",
    "    scores = clf.decision_function(df)\n",
    "    anomalousness.append((scores[len(df_normal)], i))\n",
    "\n",
    "# sort anomalousness by the first element of each tuple from least to greatest\n",
    "anomalousness.sort(key=lambda x: x[0])\n",
    "for i in range(len(anomalousness)):\n",
    "    print(anomalousness[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
